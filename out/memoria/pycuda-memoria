

Trabajo con PyCUDA

1. Primeras pruebas

Durante el tiempo que hemos trabajado con PyCUDA en el último cuatrimestre, hemos implementado varios algoritmos de diferente complejidad. Inicialmente, nuestro objetivo consistió en familiarizarnos tanto con el entorno de trabajo como con una arquitectura que no habíamos empleado hasta ahora. Para ello, comenzamos escribiendo kernels que ejecutaban tareas sencillas tales como multiplicar un escalar por un vector, sumar dos vectores, etc. Este tipo de aplicaciones, aún cuando resultaron más eficientes ejecutados sobre la CPU que sobre la GPU en las mayoría de las pruebas --la gráfica solo alcanzaba mayor velocidad a partir de los 10.000 elementos-- , nos permitieron comprender la importancia de indicar el número adecuado de hilos por bloque o el tamaño del grid correcto tanto para acelerar el propio cálculo como para evitar los accesos no coalescentes a memoria. Huelga decir que en el caso anterior, la menor velocidad de la GPU se debe al tiempo empleado en la transferencia de datos de la memoria principal a la memoria del dispositivo y no al cómputo en sí.

A continuación, abordamos dos problemas característicos: el producto matricial y la aplicación de un filtro de imagen. La manera tradicional de abordar la multiplicación de matrices pasa por ejecutar un algoritmo secuencial con un orden de complejidad casi cúbico en las mejores implementaciones. Dado que este algoritmo puede ser paralelizado sin mucha dificultad, nos planteamos su ejecución con PyCUDA para cruzar su eficiencia con la de su correspondiente versión de CPU. Nuestro banco de pruebas consistió en una serie de 8 multiplicaciones de matrices cuadradas generadas aleatoriamente. Las dimensiones de dichas matrices fueron incrementándose en 4 tras cada multiplicación, desde 4 hasta 32. Los datos obtenidos, que se recogen en el siguiente gráfico, muestran que la CPU solo fue más rápida en el caso de que las dos matrices tuvieran dimensión 4, mientras que el resto de los casos, no solo fue superior a la GPU (que se mantuvo prácticamente constante) sino que fue aumentando su distancia con ella a medida que el tamaño de las matrices se incrementaba.

En cuanto al filtro de imagen, nos decantamos por una implementación sencilla del filtro threshold consistente en examinar las componentes RGB de cada píxel de la imagen de entrada, saturándolo a blanco (255, 255, 255) si alguno de ellos presentaba un valor superior a 50. En este caso, comparamos la ejecución de este filtro consigo mismo, modificando sucesivamente los parámetros de la CUDA para, lanzando un hilo por cada píxel, comparar los resultados obtenidos con diferentes tamaños de bloque y de grid.

2.- Desarrollo del paquete Filters

Finalmente, escogimos como objetivo de desarrollo el diseño e implementación de un paquete que permita aplicar diferentes filtros a una imagen, a un conjunto de imágenes o a un vídeo, en cuyo caso será descompuesto en sus correspondientes frames. Este paquete puede utilizarse para acelerar el cálculo de aplicaciones complejas que requieran de la aplicación de filtros. En concreto, una de las más interesantes que hemos adaptado consiste en un programa de detección de movimiento.

El paquete Filters se estructura, esencialmente, en torno a dos clases: CUDAHandler, concebido para comunicarse con la GPU, y Filter, clase abstracta de la que heredan cada uno de los filtros implementados. En la imagen adjunta, pueden observarse tres clases hijas de Filter que contienen las instrucciones para gestionar tres filtros necesarios para la detección de movimiento (Difference, Threshold y Erosion). Además, también se contempla una clase MotionDetection, encargada de realizar la detección en sí y que hace uso del paquete Filters, además de la clase VideoHandler que la abstrae de la manipulación de las operaciones de gestión de vídeo.